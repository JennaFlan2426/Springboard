{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thinking out loud, at the beginning:\n",
    "- Wow these files are big, I'm going to need to pare down the data probably a lot.\n",
    "- First going to be looking for \"what's the most complete data that I have for what span of time\"?\n",
    "- What data do I actually want to focus on? (record some research on how, broadly, one comes up with a company valuation that could be comparable to market capitalization)\n",
    "- I probably should focus my market data gathering on the day after each SEC filing is released, assuming that will be the day that stock price movements are most influenced by the filing information rather than other news or factors.\n",
    "- My core question so far is, are market prices correlated with valuation information in some fashion?\n",
    "    - If so, which valuation information is most strongly correlated?\n",
    "    - What, if any, is the relationship between stock price/market capitalization and the business's balance sheet?\n",
    "    - Do any of these data include attempts to put a value on intangibles such as goodwill/reputation?\n",
    "    - The fundamental analysis tradition focuses on ratios of price to earnings, book value, earnings growth; do the ratios that investors find acceptable change over time? Do they tend to change back (or ahead) when SEC filings are released?\n",
    "    - (Do I have time for this?) What happens in the periods between filings? Do prices maintain a range, like the moving average support/resistance bands favored by technical analysis?\n",
    "- Therefore, what am I looking for in the data I've found so far?\n",
    "    - As much history as I can assemble from both market data and SEC filings; will need to drop years where I have one but not the other.\n",
    "    - Focus on the Fortune 100, probably choose the 100 as of the most recent year I have data for.\n",
    "    - Market data at daily granularity, hopefully with open, high, low, and close prices for each day. Probably focus on dates related to the company's SEC filings.\n",
    "    - Still deciding what SEC filing information, partially I don't know what I have to work with yet, hoping for a moderately quick thumbnail of value related to assets, liabilities, and maybe intangibles/goodwill. Assuming earnings-per-share numbers also will be found here.\n",
    "    - If market data has already calculated P/E or other ratios, great, I can use those to sanity-check what I'm pulling in from SEC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First crack at a plan:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open each dataset (I have 4 right now) individually, probably not in code. \n",
    "- Need to see file structure and years covered. Make decision on how much history to collect/collate.\n",
    "    - Market datasets from:\n",
    "        - https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs\n",
    "            - description does not offer a begin date but last updated in 2017-Nov\n",
    "            - data appears to be in txt files by ticker: file for AAPL dates to 1984-Sep and columns are Date,Open,High,Low,Close,Volume,OpenInt\n",
    "            - there is a comment that prices in this data are adjusted for dividends AND splits (as opposed to Yahoo Finance data, which is not or not always--not sure what that means)\n",
    "        - https://www.kaggle.com/tsaustin/us-historical-stock-prices-with-earnings-data\n",
    "            - 20 years according to description; last updated 2020-Dec\n",
    "            - Data in 4 files: stock price, earnings (estimated and reported), dividends, and a summary\n",
    "    - SEC datasets from:\n",
    "        - https://www.kaggle.com/miguelaenlle/parsed-sec-10q-filings-since-2006\n",
    "            - Since 2006 according to description; Last updated 2020-Jul\n",
    "            - Notes that ~50% of data is null, which might be 'not found in filing' or 'not found by parser'.\n",
    "            - Does have lots of promising columns like commonstocksharesissued, assetscurrent, accountspayablecurrent, commonstockvalue, liabilities, liabilitiesandstockholdersequity, stockholdersequity, earningspersharebasic, netincomeloss, profitloss, costofgoodssold, filing_date, costsandexpenses, cash \n",
    "        - https://www.kaggle.com/finnhub/reported-financials\n",
    "            - 2010-2020, according to description. Last updated 2021-Mar\n",
    "            - 4 GB data!\n",
    "            - Data is in folders by year-qtr; JSON files. Will take some work, I think, to find the tickers I want.\n",
    "            \n",
    "So, I can probably get 2010-2020 reasonably complete. Maybe 2006-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# lots of code will depend on this ticker list\n",
    "ticker_list = ['AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open each dataset in code and examine columns.\n",
    "See if I can choose one market and one SEC dataset; do they contain the same information? Is there just a column or two from one I can add to the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: the Finnhub SEC filings dataset\n",
    "- Hopefully the most complicated one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Value Error: Value is too big\n",
      "Value Error1: Expected object or value\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Found one!\n",
      "Files found: 44\n",
      "Problem files found: 2\n"
     ]
    }
   ],
   "source": [
    "# Note some of this code may not work as written except on my own computer, or if you download the datasets like I did.\n",
    "# Not planning to upload all this data, it's waaay too much.\n",
    "# CAUTION: walking all this data will take a long time! Over 200K files, expect 20+ min of \"busy\" before you get an answer.\n",
    "# I am grateful that Jupyter changes the tab icon to hourglass when a notebook is busy!\n",
    "\n",
    "# For Finnhub reported-financials dataset:\n",
    "# Recurse through many YYYY.Q# subdirectories using os.walk\n",
    "# Acquire list of files containing the ticker(s) I want (define a list somewhere early!)\n",
    "# Copy those files to a \"data I'm keeping\" folder\n",
    "# Import reduced file set into a dataframe for analysis\n",
    "# I thought about defining a function, but it's pretty specific to how this one dataset is laid out, is it worth it?\n",
    "\n",
    "\n",
    "start_dir = os.path.join(os.getcwd(), 'SEC-FinancialsAsReported') \n",
    "files_list = []\n",
    "problem_files = []\n",
    "\n",
    "for root, subdirs, files in os.walk(start_dir):\n",
    "    for filename in files:\n",
    "        if os.path.splitext(filename)[1] == ('.json'):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                df = pd.read_json(file_path) # is there a better way to read json if all I want is to check one column?\n",
    "            except ValueError as val_err:\n",
    "                problem_files.append((file_path, \"Value Error: {0}\".format(val_err)))\n",
    "            except:\n",
    "                print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                raise\n",
    "            else:\n",
    "                set_tickers = set(ticker_list)\n",
    "                set_symbols = set(df['symbol'].unique())\n",
    "                if set_tickers.intersection(set_symbols):\n",
    "                    # print('Found one!')\n",
    "                    files_list.append(file_path)\n",
    "\n",
    "print('Files found: ' + str(len(files_list)))\n",
    "print('Problem files found: ' + str(len(problem_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experimenting with the one problem file. Set lines? orient? skip because it's one file out of 200K or so?\n",
    "'''\n",
    "print(os.getcwd())\n",
    "file_problem = os.path.join(os.getcwd(),'SEC-FinancialsAsReported\\\\2016.QTR4\\\\0001098009-16-000023.json')\n",
    "print(file_problem)\n",
    "'''\n",
    "# tried a lot of variations to get path join to work by hand (as opposed to using walk). \n",
    "# The two most important seem to be start with os.getcwd() and escape any slashes in the path.\n",
    "\n",
    "'''\n",
    "df = pd.read_json(file_problem) #as done in filewalk above, \"value is too big\"\n",
    "df = pd.read_json(file_problem, lines=True) #did not work, \"expected object or value\"\n",
    "df = pd.read_json(file_problem, orient='records') #did not work, \"value is too big\"\n",
    "df = pd.read_json(file_problem, orient='split') #did not work, \"value is too big\"\n",
    "df = pd.read_json(file_problem, orient='index') #did not work, \"value is too big\"\n",
    "df = pd.read_json(file_problem, orient='columns') #did not work, \"value is too big\"\n",
    "df = pd.read_json(file_problem, orient='values') #did not work, \"value is too big\"\n",
    "print(df.head)\n",
    "'''\n",
    "# nothing is working so far, skip this damn file. Opened in Notepad++ and its ticker is 'CWNM' \n",
    "# which I don't think is on my list anyway.\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, to see what I have for my ticker(s) in finnhub files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               label  \\\n",
      "0                    Long-term marketable securities   \n",
      "1  Tangible assets that are held by an entity for...   \n",
      "2                                           Goodwill   \n",
      "3                    Acquired intangible assets, net   \n",
      "4                                       Other assets   \n",
      "\n",
      "                                             concept unit        value  \\\n",
      "0               AvailableForSaleSecuritiesNoncurrent  usd  18549000000   \n",
      "1  aapl:PropertyPlantAndEquipmentAndCapitalizedSo...  usd   3504000000   \n",
      "2                                           Goodwill  usd    480000000   \n",
      "3               IntangibleAssetsNetExcludingGoodwill  usd    263000000   \n",
      "4                              OtherAssetsNoncurrent  usd   1925000000   \n",
      "\n",
      "    startDate     endDate  year quarter symbol  \n",
      "0  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "1  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "2  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "3  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "4  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   label      25 non-null     object\n",
      " 1   concept    25 non-null     object\n",
      " 2   unit       25 non-null     object\n",
      " 3   value      25 non-null     int64 \n",
      " 4   startDate  25 non-null     object\n",
      " 5   endDate    25 non-null     object\n",
      " 6   year       25 non-null     object\n",
      " 7   quarter    25 non-null     object\n",
      " 8   symbol     25 non-null     object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "              value\n",
      "count  2.500000e+01\n",
      "mean   1.319400e+10\n",
      "std    1.698961e+10\n",
      "min    1.250000e+08\n",
      "25%    1.925000e+09\n",
      "50%    4.539000e+09\n",
      "75%    1.770900e+10\n",
      "max    5.705700e+10\n"
     ]
    }
   ],
   "source": [
    "# concat/map solution found at https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "#finnhub_df = pd.concat(map(pd.read_json, files_list))\n",
    "# not working well due to nested JSON, I think...\n",
    "\n",
    "# json_normalize found at https://stackoverflow.com/questions/20638006/convert-list-of-dictionaries-to-a-pandas-dataframe\n",
    "# convert to dict clue found at https://stackoverflow.com/questions/55710154/python-json-normalize-string-indices-must-be-integers-error\n",
    "# nested JSON clue 1: https://stackoverflow.com/questions/47341519/json-normalize-for-dicts-within-dicts\n",
    "# nested JSON clue 2: https://stackoverflow.com/questions/46091362/how-to-normalize-json-correctly-by-python-pandas (needs json.load)\n",
    "# nested JSON clue 3: https://www.kaggle.com/jboysen/quick-tutorial-flatten-nested-json-in-pandas/notebook\n",
    "\n",
    "for i in range(len(files_list)):\n",
    "    with open(files_list[i]) as f:\n",
    "        d = json.load(f)\n",
    "    if i == 0:\n",
    "        balsheet_df = pd.json_normalize(d, record_path=['data','bs'], meta=['startDate','endDate','year','quarter','symbol'])\n",
    "        cashflow_df = pd.json_normalize(d, record_path=['data','cf'], meta=['startDate','endDate','year','quarter','symbol'])\n",
    "        income_df = pd.json_normalize(d, record_path=['data','ic'], meta=['startDate','endDate','year','quarter','symbol'])\n",
    "    else:\n",
    "        balsheet_df.append(pd.json_normalize(d, record_path=['data','bs'], meta=['startDate','endDate','year','quarter','symbol']))\n",
    "        cashflow_df.append(pd.json_normalize(d, record_path=['data','cf'], meta=['startDate','endDate','year','quarter','symbol']))\n",
    "        income_df.append(pd.json_normalize(d, record_path=['data','ic'], meta=['startDate','endDate','year','quarter','symbol']))\n",
    "\n",
    "print(balsheet_df.head())\n",
    "print(balsheet_df.info())\n",
    "print(balsheet_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               label  \\\n",
      "0           Depreciation, amortization and accretion   \n",
      "1                   Stock-based compensation expense   \n",
      "2                        Deferred income tax expense   \n",
      "3  Loss on disposition of property, plant and equ...   \n",
      "4                           Accounts receivable, net   \n",
      "\n",
      "                                   concept unit      value   startDate  \\\n",
      "0  DepreciationAmortizationAndAccretionNet  usd  425000000  2009-09-27   \n",
      "1                   ShareBasedCompensation  usd  436000000  2009-09-27   \n",
      "2          DeferredIncomeTaxExpenseBenefit  usd  893000000  2009-09-27   \n",
      "3   GainLossOnSaleOfPropertyPlantEquipment  usd   -9000000  2009-09-27   \n",
      "4     IncreaseDecreaseInAccountsReceivable  usd -482000000  2009-09-27   \n",
      "\n",
      "      endDate  year quarter symbol  \n",
      "0  2010-03-27  2010      Q2   AAPL  \n",
      "1  2010-03-27  2010      Q2   AAPL  \n",
      "2  2010-03-27  2010      Q2   AAPL  \n",
      "3  2010-03-27  2010      Q2   AAPL  \n",
      "4  2010-03-27  2010      Q2   AAPL  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   label      28 non-null     object\n",
      " 1   concept    28 non-null     object\n",
      " 2   unit       28 non-null     object\n",
      " 3   value      28 non-null     int64 \n",
      " 4   startDate  28 non-null     object\n",
      " 5   endDate    28 non-null     object\n",
      " 6   year       28 non-null     object\n",
      " 7   quarter    28 non-null     object\n",
      " 8   symbol     28 non-null     object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "              value\n",
      "count  2.800000e+01\n",
      "mean   2.473536e+09\n",
      "std    5.659893e+09\n",
      "min   -4.041000e+09\n",
      "25%   -1.125000e+07\n",
      "50%    4.305000e+08\n",
      "75%    1.205750e+09\n",
      "max    2.506100e+10\n"
     ]
    }
   ],
   "source": [
    "print(cashflow_df.head())\n",
    "print(cashflow_df.info())\n",
    "print(cashflow_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 label  \\\n",
      "0            Earnings Per Share, Basic   \n",
      "1          Earnings Per Share, Diluted   \n",
      "2             Research and development   \n",
      "3  Selling, general and administrative   \n",
      "4             Total operating expenses   \n",
      "\n",
      "                                  concept        unit         value  \\\n",
      "0                   EarningsPerShareBasic  usd/shares  7.120000e+00   \n",
      "1                 EarningsPerShareDiluted  usd/shares  7.000000e+00   \n",
      "2           ResearchAndDevelopmentExpense         usd  8.240000e+08   \n",
      "3  SellingGeneralAndAdministrativeExpense         usd  2.508000e+09   \n",
      "4                       OperatingExpenses         usd  3.332000e+09   \n",
      "\n",
      "    startDate     endDate  year quarter symbol  \n",
      "0  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "1  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "2  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "3  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "4  2009-09-27  2010-03-27  2010      Q2   AAPL  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   label      15 non-null     object \n",
      " 1   concept    15 non-null     object \n",
      " 2   unit       15 non-null     object \n",
      " 3   value      15 non-null     float64\n",
      " 4   startDate  15 non-null     object \n",
      " 5   endDate    15 non-null     object \n",
      " 6   year       15 non-null     object \n",
      " 7   quarter    15 non-null     object \n",
      " 8   symbol     15 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "              value\n",
      "count  1.500000e+01\n",
      "mean   6.214392e+09\n",
      "std    8.154571e+09\n",
      "min    7.000000e+00\n",
      "25%    8.647725e+08\n",
      "50%    2.508000e+09\n",
      "75%    8.745500e+09\n",
      "max    2.918200e+10\n"
     ]
    }
   ],
   "source": [
    "print(income_df.head())\n",
    "print(income_df.info())\n",
    "print(income_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some things I needed to find out:\n",
    "- Why are all these reports split into records called \"bs/cf/ic\"? What are those abbreviations for?\n",
    "- how about... **B**alance **S**heet, **C**ash **F**low, **I**n**C**ome statement? https://www.sec.gov/oiea/reportspubs/investor-publications/beginners-guide-to-financial-statements.html\n",
    "- I want to see more of what's in those \"data\" fields: learning how to unpack nested JSON\n",
    "- Describe doesn't do much when every number is a different thing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TODO:*** code to save the files to a location I'm willing to upload, code to save the dataframes for later, melt these dataframes and see where the commonalities are (group/sort by label and/or concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. The miguelaenlle SEC dataset \"Historical Financials\"\n",
    "- Should be far less complicated! Everything in one CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39 entries, 203 to 241\n",
      "Data columns (total 44 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   commonstocksharesissued           39 non-null     float64\n",
      " 1   assetscurrent                     39 non-null     float64\n",
      " 2   accountspayablecurrent            39 non-null     float64\n",
      " 3   commonstockvalue                  24 non-null     float64\n",
      " 4   liabilities                       39 non-null     float64\n",
      " 5   liabilitiesandstockholdersequity  39 non-null     float64\n",
      " 6   stockholdersequity                39 non-null     float64\n",
      " 7   earningspersharebasic             39 non-null     float64\n",
      " 8   netincomeloss                     39 non-null     float64\n",
      " 9   profitloss                        0 non-null      float64\n",
      " 10  costofgoodssold                   0 non-null      float64\n",
      " 11  filing_date                       39 non-null     object \n",
      " 12  costsandexpenses                  0 non-null      float64\n",
      " 13  cash                              11 non-null     float64\n",
      " 14  notespayable                      0 non-null      float64\n",
      " 15  preferredstockvalue               0 non-null      float64\n",
      " 16  depreciation                      0 non-null      float64\n",
      " 17  operatingexpenses                 39 non-null     float64\n",
      " 18  revenues                          5 non-null      float64\n",
      " 19  land                              0 non-null      float64\n",
      " 20  accountsreceivablenet             0 non-null      float64\n",
      " 21  deferredrevenue                   0 non-null      float64\n",
      " 22  grossprofit                       39 non-null     float64\n",
      " 23  sharesissued                      7 non-null      float64\n",
      " 24  accruedincometaxes                0 non-null      float64\n",
      " 25  sharesoutstanding                 0 non-null      float64\n",
      " 26  borrowedfunds                     0 non-null      float64\n",
      " 27  inventorygross                    0 non-null      float64\n",
      " 28  commercialpaper                   39 non-null     float64\n",
      " 29  dividends                         39 non-null     float64\n",
      " 30  commonstocknoparvalue             0 non-null      float64\n",
      " 31  costofservices                    0 non-null      float64\n",
      " 32  debtcurrent                       0 non-null      float64\n",
      " 33  accruedinsurancecurrent           0 non-null      float64\n",
      " 34  officerscompensation              0 non-null      float64\n",
      " 35  intangibleassetscurrent           0 non-null      float64\n",
      " 36  salariesandwages                  0 non-null      float64\n",
      " 37  interestanddebtexpense            0 non-null      float64\n",
      " 38  convertibledebt                   0 non-null      float64\n",
      " 39  assetmanagementcosts              0 non-null      float64\n",
      " 40  accountsreceivablegross           0 non-null      float64\n",
      " 41  directoperatingcosts              0 non-null      float64\n",
      " 42  operatingcycle                    0 non-null      object \n",
      " 43  stock                             39 non-null     object \n",
      "dtypes: float64(41), object(3)\n",
      "memory usage: 13.7+ KB\n",
      "None\n",
      "       commonstocksharesissued  assetscurrent  accountspayablecurrent  \\\n",
      "count             3.900000e+01   3.900000e+01            3.900000e+01   \n",
      "mean              3.078833e+09   7.352951e+10            2.521764e+10   \n",
      "std               2.318406e+09   3.357312e+10            1.412601e+10   \n",
      "min               8.992130e+05   3.155500e+10            5.601000e+09   \n",
      "25%               9.159700e+08   4.619500e+10            1.441150e+10   \n",
      "50%               9.392080e+08   6.853100e+10            2.236700e+10   \n",
      "75%               5.295794e+09   9.787550e+10            3.311300e+10   \n",
      "max               6.294494e+09   1.438100e+11            6.298500e+10   \n",
      "\n",
      "       commonstockvalue   liabilities  liabilitiesandstockholdersequity  \\\n",
      "count      2.400000e+01  3.900000e+01                      3.900000e+01   \n",
      "mean       1.160488e+10  1.114479e+11                      2.097765e+11   \n",
      "std        4.005468e+09  8.391653e+10                      1.138337e+11   \n",
      "min        7.957000e+09  1.586100e+10                      4.750100e+10   \n",
      "25%        8.146750e+09  3.791400e+10                      1.069320e+11   \n",
      "50%        1.066800e+10  8.345100e+10                      2.070000e+11   \n",
      "75%        1.578525e+10  1.862490e+11                      3.136440e+11   \n",
      "max        2.055900e+10  2.665950e+11                      4.067940e+11   \n",
      "\n",
      "       stockholdersequity  earningspersharebasic  netincomeloss  profitloss  \\\n",
      "count        3.900000e+01              39.000000   3.900000e+01         0.0   \n",
      "mean         6.139308e+10               6.873590   1.668905e+10         NaN   \n",
      "std          4.919372e+10               4.138496   1.440487e+10         NaN   \n",
      "min         -9.530000e+08               1.290000   2.532000e+09         NaN   \n",
      "25%          1.510300e+10               3.385000   7.308000e+09         NaN   \n",
      "50%          4.779100e+10               6.530000   1.162200e+10         NaN   \n",
      "75%          1.115470e+11               9.345000   1.916300e+10         NaN   \n",
      "max          1.296840e+11              14.590000   5.953100e+10         NaN   \n",
      "\n",
      "       ...  debtcurrent  accruedinsurancecurrent  officerscompensation  \\\n",
      "count  ...          0.0                      0.0                   0.0   \n",
      "mean   ...          NaN                      NaN                   NaN   \n",
      "std    ...          NaN                      NaN                   NaN   \n",
      "min    ...          NaN                      NaN                   NaN   \n",
      "25%    ...          NaN                      NaN                   NaN   \n",
      "50%    ...          NaN                      NaN                   NaN   \n",
      "75%    ...          NaN                      NaN                   NaN   \n",
      "max    ...          NaN                      NaN                   NaN   \n",
      "\n",
      "       intangibleassetscurrent  salariesandwages  interestanddebtexpense  \\\n",
      "count                      0.0               0.0                     0.0   \n",
      "mean                       NaN               NaN                     NaN   \n",
      "std                        NaN               NaN                     NaN   \n",
      "min                        NaN               NaN                     NaN   \n",
      "25%                        NaN               NaN                     NaN   \n",
      "50%                        NaN               NaN                     NaN   \n",
      "75%                        NaN               NaN                     NaN   \n",
      "max                        NaN               NaN                     NaN   \n",
      "\n",
      "       convertibledebt  assetmanagementcosts  accountsreceivablegross  \\\n",
      "count              0.0                   0.0                      0.0   \n",
      "mean               NaN                   NaN                      NaN   \n",
      "std                NaN                   NaN                      NaN   \n",
      "min                NaN                   NaN                      NaN   \n",
      "25%                NaN                   NaN                      NaN   \n",
      "50%                NaN                   NaN                      NaN   \n",
      "75%                NaN                   NaN                      NaN   \n",
      "max                NaN                   NaN                      NaN   \n",
      "\n",
      "       directoperatingcosts  \n",
      "count                   0.0  \n",
      "mean                    NaN  \n",
      "std                     NaN  \n",
      "min                     NaN  \n",
      "25%                     NaN  \n",
      "50%                     NaN  \n",
      "75%                     NaN  \n",
      "max                     NaN  \n",
      "\n",
      "[8 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "hf_path = os.path.join(os.getcwd(), 'SEC-HistoricalFinancials', 'quarterly_financials.csv')\n",
    "hf_df = pd.read_csv(hf_path, index_col=0, low_memory=False)\n",
    "# dtype warning for mixed types in column 43?\n",
    "#print(hf_df.iloc[:, 43])\n",
    "#print(hf_df['stock'].unique())\n",
    "#print(hf_df.info())\n",
    "# maybe this is about the first ticker being 'AA$'?\n",
    "hf_tickers_df = hf_df[hf_df['stock'].isin(ticker_list)]\n",
    "print(hf_tickers_df.info())\n",
    "print(hf_tickers_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. The borismarjanovic 'Huge Dataset' of market prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open     High      Low    Close    Volume  OpenInt\n",
      "0  1984-09-07  0.42388  0.42902  0.41874  0.42388  23220030        0\n",
      "1  1984-09-10  0.42388  0.42516  0.41366  0.42134  18022532        0\n",
      "2  1984-09-11  0.42516  0.43668  0.42516  0.42902  42498199        0\n",
      "3  1984-09-12  0.42902  0.43157  0.41618  0.41618  37125801        0\n",
      "4  1984-09-13  0.43927  0.44052  0.43927  0.43927  57822062        0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8364 entries, 0 to 8363\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Date     8364 non-null   object \n",
      " 1   Open     8364 non-null   float64\n",
      " 2   High     8364 non-null   float64\n",
      " 3   Low      8364 non-null   float64\n",
      " 4   Close    8364 non-null   float64\n",
      " 5   Volume   8364 non-null   int64  \n",
      " 6   OpenInt  8364 non-null   int64  \n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 457.5+ KB\n",
      "None\n",
      "              Open         High          Low        Close        Volume  \\\n",
      "count  8364.000000  8364.000000  8364.000000  8364.000000  8.364000e+03   \n",
      "mean     22.284350    22.495867    22.054244    22.281018  1.066416e+08   \n",
      "std      37.763402    38.057733    37.447432    37.764469  9.935187e+07   \n",
      "min       0.233050     0.235640     0.230510     0.230510  0.000000e+00   \n",
      "25%       1.137100     1.164200     1.112800     1.137100  4.384365e+07   \n",
      "50%       1.632800     1.663400     1.600600     1.628250  7.481383e+07   \n",
      "75%      23.739000    23.930500    23.335750    23.694500  1.320534e+08   \n",
      "max     175.110000   175.610000   174.270000   175.610000  2.069770e+09   \n",
      "\n",
      "       OpenInt  \n",
      "count   8364.0  \n",
      "mean       0.0  \n",
      "std        0.0  \n",
      "min        0.0  \n",
      "25%        0.0  \n",
      "50%        0.0  \n",
      "75%        0.0  \n",
      "max        0.0  \n"
     ]
    }
   ],
   "source": [
    "hd_path = os.path.join(os.getcwd(), 'Market-HugeDataset', 'Stocks')\n",
    "hd_filelist = []\n",
    "for ticker in ticker_list:\n",
    "    filename = ticker.lower() + '.us.txt'\n",
    "    hd_filelist.append(os.path.join(hd_path, filename))\n",
    "    \n",
    "# concat/map solution found at https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "hd_df = pd.concat(map(pd.read_csv, hd_filelist))\n",
    "print(hd_df.head())\n",
    "print(hd_df.info())\n",
    "print(hd_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do I believe these prices? OK, a quick search says today's price was `$`134.16 at last close. Wonder if I'll see what the effect of adjustment is by comparing with the next dataset? I'm pretty sure I've noticed AAPL's price being higher than $175 in my random contacts with stock market reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. The tsaustin 'Historical Prices' market dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol  total_prices stock_from_date stock_to_date  total_earnings  \\\n",
      "16   AAPL          5756      1998-01-02    2020-11-13              46   \n",
      "\n",
      "   earnings_from_date earnings_to_date  \n",
      "16         2009-07-21       2020-10-29  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1 entries, 16 to 16\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   symbol              1 non-null      object\n",
      " 1   total_prices        1 non-null      int64 \n",
      " 2   stock_from_date     1 non-null      object\n",
      " 3   stock_to_date       1 non-null      object\n",
      " 4   total_earnings      1 non-null      int64 \n",
      " 5   earnings_from_date  1 non-null      object\n",
      " 6   earnings_to_date    1 non-null      object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 64.0+ bytes\n",
      "None\n",
      "    symbol        date      qtr  eps_est   eps release_time\n",
      "357   AAPL  2009-07-21  06/2009      NaN   NaN         post\n",
      "358   AAPL  2009-10-19  09/2009      NaN  0.45         post\n",
      "359   AAPL  2010-01-25  12/2009      NaN   NaN         post\n",
      "360   AAPL  2010-04-20  03/2010      NaN   NaN         post\n",
      "361   AAPL  2010-07-20  06/2010      NaN   NaN         post\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46 entries, 357 to 402\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   symbol        46 non-null     object \n",
      " 1   date          46 non-null     object \n",
      " 2   qtr           46 non-null     object \n",
      " 3   eps_est       33 non-null     float64\n",
      " 4   eps           34 non-null     float64\n",
      " 5   release_time  39 non-null     object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "   symbol        date  dividend\n",
      "56   AAPL  2014-08-07      0.47\n",
      "57   AAPL  2016-11-03      0.57\n",
      "58   AAPL  2016-08-04      0.57\n",
      "59   AAPL  2012-11-07      2.65\n",
      "60   AAPL  2017-02-09      0.57\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34 entries, 56 to 250078\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   symbol    34 non-null     object \n",
      " 1   date      34 non-null     object \n",
      " 2   dividend  34 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.1+ KB\n",
      "None\n",
      "     symbol        date    open    high     low   close  close_adjusted  \\\n",
      "4544   AAPL  2017-06-29  144.71  145.13  142.28  143.68        142.5853   \n",
      "4545   AAPL  2007-03-21   91.99   94.00   91.65   93.87         12.0203   \n",
      "4546   AAPL  2002-08-14   14.67   15.35   14.54   15.17          0.9713   \n",
      "4547   AAPL  2005-09-28   53.07   53.11   50.59   51.08          6.5409   \n",
      "4548   AAPL  2017-10-23  156.89  157.69  155.50  156.17        155.6088   \n",
      "\n",
      "        volume  split_coefficient  \n",
      "4544  31116980                1.0  \n",
      "4545  24532000                1.0  \n",
      "4546   7126500                1.0  \n",
      "4547  40198000                1.0  \n",
      "4548  21654461                1.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5756 entries, 4544 to 23520102\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   symbol             5756 non-null   object \n",
      " 1   date               5756 non-null   object \n",
      " 2   open               5756 non-null   float64\n",
      " 3   high               5756 non-null   float64\n",
      " 4   low                5756 non-null   float64\n",
      " 5   close              5756 non-null   float64\n",
      " 6   close_adjusted     5756 non-null   float64\n",
      " 7   volume             5756 non-null   int64  \n",
      " 8   split_coefficient  5756 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 449.7+ KB\n",
      "None\n",
      "              open         high          low        close  close_adjusted  \\\n",
      "count  5756.000000  5756.000000  5756.000000  5756.000000     5756.000000   \n",
      "mean    165.189979   167.067579   163.194326   165.182120       60.791058   \n",
      "std     157.709647   159.005074   156.207535   157.642355       78.968162   \n",
      "min      12.990000    13.190000    12.720000    13.120000        0.498700   \n",
      "25%      43.000000    43.927500    42.335000    42.997500        2.341125   \n",
      "50%     114.220000   115.715000   112.540050   114.105000       23.008450   \n",
      "75%     205.760000   207.772500   203.715000   205.945000       96.852350   \n",
      "max     702.410000   705.070000   699.570000   702.100000      506.090000   \n",
      "\n",
      "             volume  split_coefficient  \n",
      "count  5.756000e+03        5756.000000  \n",
      "mean   2.343400e+07           1.001911  \n",
      "std    2.277948e+07           0.090350  \n",
      "min    6.488270e+05           1.000000  \n",
      "25%    7.346625e+06           1.000000  \n",
      "50%    1.880440e+07           1.000000  \n",
      "75%    3.155277e+07           1.000000  \n",
      "max    3.326072e+08           7.000000  \n"
     ]
    }
   ],
   "source": [
    "hp_filepath = os.path.join(os.getcwd(), 'Market-HistoricalPrices')\n",
    "hp_df_s = pd.read_csv(os.path.join(hp_filepath, 'dataset_summary.csv'))\n",
    "hp_df_tckr_s = hp_df_s[hp_df_s['symbol'].isin(ticker_list)]\n",
    "print(hp_df_tckr_s.head())\n",
    "print(hp_df_tckr_s.info())\n",
    "hp_df_e = pd.read_csv(os.path.join(hp_filepath, 'stocks_latest', 'earnings_latest.csv'))\n",
    "hp_df_tckr_e = hp_df_e[hp_df_e['symbol'].isin(ticker_list)]\n",
    "print(hp_df_tckr_e.head())\n",
    "print(hp_df_tckr_e.info())\n",
    "hp_df_d = pd.read_csv(os.path.join(hp_filepath, 'stocks_latest', 'dividends_latest.csv'))\n",
    "hp_df_tckr_d = hp_df_d[hp_df_d['symbol'].isin(ticker_list)]\n",
    "print(hp_df_tckr_d.head())\n",
    "print(hp_df_tckr_d.info())\n",
    "hp_df_p = pd.read_csv(os.path.join(hp_filepath, 'stocks_latest', 'stock_prices_latest.csv'))\n",
    "hp_df_tckr_p = hp_df_p[hp_df_p['symbol'].isin(ticker_list)]\n",
    "print(hp_df_tckr_p.head())\n",
    "print(hp_df_tckr_p.info())\n",
    "print(hp_df_tckr_p.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? This one suggests much higher max prices. What's going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Choose 100 companies and pull their data into new files to reduce data sizes. \n",
    "Let's try the 2020 Fortune 100.\n",
    "Data retrieved from https://fortune.com/fortune500/2020/search/?rank=asc\n",
    "Spent a bunch of time massaging the text as copied back into tabular format. Spent a bunch more time going through each company's profile page to pull out ticker symbols. Hopefully an employer would have a better way to access the data, but it's good enough for this project. They want \\$500 or more for a data file and don't talk about having an API that I can see.\n",
    "\n",
    "- Some ticker notes:\n",
    "    - There are a bunch of companies (especially mutual insurance companies) without tickers, so I'm going to end up with less than 100 companies. Expand search or leave it?\n",
    "    - Will I need to look out for name changes (esp ticker changes)?\n",
    "    - Albertsons has a ticker but IPO was last year sometime so may not have data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Begin EDA, look for cleaning needs. \n",
    "- Figure out how best to pull only the SEC-related dates of market data, assuming that dates will generally be different for each company.\n",
    "- Calculate (can I sanity-check somehow?) fundamental analysis ratios: P/E, P/E/G, price/book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tasks as I think of them while exploring!\n",
    "- Do I have data that shows market capitalization? Or shares outstanding, so I can calculate?\n",
    "- How does one adjust prices for dividends, splits? What price do I need to use to calculate ratios, market cap, etc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for later:\n",
    "- Once I produce something with this, should I share it on Kaggle? If I've combined datasets, can I link my code to both of them?\n",
    "- Can or should I try to confirm that Yahoo Finance is a bad place to get stock data from? (see notes on first market dataset above)\n",
    "- How do I pull out the data I want from these JSON files and save for later? As dataframe, csv, something else?\n",
    "- Can I pull additional company data from the Fortune site? Should I? https://fortune.com/company/stonex-group/fortune500/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research:\n",
    "- https://www.investopedia.com/terms/a/adjusted_closing_price.asp\n",
    "- https://www.investopedia.com/articles/fundamental-analysis/08/sec-forms.asp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
